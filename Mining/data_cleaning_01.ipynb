{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b3b75a",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e3a618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"TestSpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.range(10)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cdf8b5",
   "metadata": {},
   "source": [
    "## Exercise 1 : Inspect and clean the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fcef496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules, and create the SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BookCF_Project\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d539ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- book_title: string (nullable = true)\n",
      " |-- book_author: string (nullable = true)\n",
      " |-- year_of_publication: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- img_s: string (nullable = true)\n",
      " |-- img_m: string (nullable = true)\n",
      " |-- img_l: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n",
      "Raw row count: 515339\n"
     ]
    }
   ],
   "source": [
    "# import Book.cvs\n",
    "file_path = \"data/Books.csv\"  \n",
    "df_raw = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# check the schema\n",
    "df_raw.printSchema()\n",
    "\n",
    "# get the number of total rows\n",
    "print(\"Raw row count:\", df_raw.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8e0fa",
   "metadata": {},
   "source": [
    "1. Clean `ISBN` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28216c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|isbn_clean|isbn_count|\n",
      "+----------+----------+\n",
      "| 971880107|      2501|\n",
      "| 316666343|      1295|\n",
      "| 385504209|       883|\n",
      "|  60928336|       732|\n",
      "| 312195516|       723|\n",
      "| 044023722|       647|\n",
      "| 142001740|       615|\n",
      "| 067976402|       614|\n",
      "| 671027360|       586|\n",
      "| 446672211|       585|\n",
      "+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "After ISBN cleaning + freq>=2, rows: 101786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# only keep figures\n",
    "df1 = df_raw.withColumn(\n",
    "    \"isbn_clean\",\n",
    "    F.regexp_replace(F.col(\"isbn\"), \"[^0-9]\", \"\")\n",
    ")\n",
    "\n",
    "# drop the blank cells\n",
    "df1 = df1.filter(F.length(F.col(\"isbn_clean\")) > 0)\n",
    "\n",
    "# count non-empty ISBN\n",
    "isbn_counts = df1.groupBy(\"isbn_clean\").agg(F.count(\"*\").alias(\"isbn_count\"))\n",
    "isbn_counts.orderBy(F.col(\"isbn_count\").desc()).show(10)\n",
    "\n",
    "# keep ISBN which appears >= 2 times\n",
    "isbn_keep = isbn_counts.filter(F.col(\"isbn_count\") >= 2).select(\"isbn_clean\")\n",
    "\n",
    "df1 = df1.join(isbn_keep, on=\"isbn_clean\", how=\"inner\")\n",
    "\n",
    "# update\n",
    "df1 = df1.drop(\"isbn\").withColumnRenamed(\"isbn_clean\", \"isbn\")\n",
    "\n",
    "print(\"After ISBN cleaning + freq>=2, rows:\", df1.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a0fd1",
   "metadata": {},
   "source": [
    "2. We selected these columns `user_id`, `isbn`, `rating`, `book_title`, `book_author`, `year_of_poblication`, `publisher`, `Summary`, `Language`, `Category` to analyze and dropped the remaining columns, including demographics (`location`, `age`, `state`, `country`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0d1a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- book_title: string (nullable = true)\n",
      " |-- book_author: string (nullable = true)\n",
      " |-- year_of_publication: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the index row\n",
    "df1 = df1.drop(\"_c0\")\n",
    "\n",
    "ratings_raw = df1.select(\n",
    "    \"user_id\",\n",
    "    \"isbn\",\n",
    "    \"rating\",\n",
    "    \"book_title\",\n",
    "    \"book_author\",\n",
    "    \"year_of_publication\",\n",
    "    \"publisher\",\n",
    "    \"Summary\",\n",
    "    \"Language\",\n",
    "    \"Category\"\n",
    ")\n",
    "\n",
    "ratings_raw.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1c2b4",
   "metadata": {},
   "source": [
    "3. Clean `rating`:  \n",
    "**Step 5 in the PDF given by prof <- moved earlier to ensure data validity**\n",
    "- string -> float[0,10]\n",
    "- remove invaild ratings\n",
    "- keep the rating 0, but it will be treated as \"no rating\" in the collaborative filtering stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a08a671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row number: 101786\n",
      "Row number with valided rating: 101562\n",
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|   0.0|59056|\n",
      "|   1.0|  200|\n",
      "|   2.0|  296|\n",
      "|   3.0|  591|\n",
      "|   4.0|  771|\n",
      "|   5.0| 3716|\n",
      "|   6.0| 3077|\n",
      "|   7.0| 6833|\n",
      "|   8.0|10632|\n",
      "|   9.0| 7918|\n",
      "|  10.0| 8472|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# string -> float[0,10]\n",
    "ratings_num = ratings_raw.withColumn(\n",
    "    \"rating\",\n",
    "    F.col(\"rating\").cast(\"float\")\n",
    ")\n",
    "\n",
    "# remove invaild ratings\n",
    "ratings_valid = ratings_num.filter(\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"rating\") >= 0.0) &\n",
    "    (F.col(\"rating\") <= 10.0)\n",
    ")\n",
    "\n",
    "print(\"Original row number:\", ratings_raw.count())\n",
    "print(\"Row number with valided rating:\", ratings_valid.count())\n",
    "\n",
    "ratings_valid.groupBy(\"rating\").count().orderBy(\"rating\").show(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095b020",
   "metadata": {},
   "source": [
    "4. Count the number of ratings for each user and only retain active users who give >= 5 ratings\n",
    "\n",
    "Users with fewer than 5 ratings are removed because Pearson correlation requires enough observations to be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b541ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|user_id|num_ratings|\n",
      "+-------+-----------+\n",
      "|  11676|        664|\n",
      "|    254|        280|\n",
      "|  35859|        255|\n",
      "|  16795|        222|\n",
      "| 153662|        208|\n",
      "|  76352|        203|\n",
      "| 230522|        202|\n",
      "|  60244|        196|\n",
      "|  55492|        187|\n",
      "| 204864|        184|\n",
      "+-------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Active user number: 3876\n",
      "Total rating number after retaining only active users: 66703\n"
     ]
    }
   ],
   "source": [
    "user_activity = ratings_valid.groupBy(\"user_id\").agg(F.count(\"*\").alias(\"num_ratings\"))\n",
    "\n",
    "user_activity.orderBy(F.col(\"num_ratings\").desc()).show(10)\n",
    "\n",
    "users_active = user_activity.filter(F.col(\"num_ratings\") >= 5)\n",
    "\n",
    "print(\"Active user number:\", users_active.count())\n",
    "\n",
    "ratings_active = ratings_valid.join(\n",
    "    users_active.select(\"user_id\"),\n",
    "    on=\"user_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Total rating number after retaining only active users:\", ratings_active.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f2817",
   "metadata": {},
   "source": [
    "5. Only retain users whose rated books overlap with others by at least one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20116b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with at least one overlapping book: 3876\n",
      "Rows after removing isolated users: 66703\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "|user_id|   isbn|rating|  book_title|         book_author|year_of_publication|           publisher|             Summary|Language|Category|\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "|      8|2005018|   5.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|  11400|2005018|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|  11676|2005018|   8.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|  85526|2005018|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|  96054|2005018|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only reamain books rated by 2 or more users \n",
    "book_user_counts = ratings_active.groupBy(\"isbn\") \\\n",
    "    .agg(F.countDistinct(\"user_id\").alias(\"num_users_for_book\"))\n",
    "\n",
    "overlap_books = book_user_counts.filter(F.col(\"num_users_for_book\") >= 2) \\\n",
    "    .select(\"isbn\")\n",
    "\n",
    "# All users related these books\n",
    "ratings_on_overlap_books = ratings_active.join(overlap_books, on=\"isbn\", how=\"inner\")\n",
    "overlap_users = ratings_on_overlap_books.select(\"user_id\").distinct()\n",
    "\n",
    "print(\"Users with at least one overlapping book:\", overlap_users.count())\n",
    "\n",
    "# In the original active rating table, only retain the ratings of overlap_users \n",
    "ratings_overlap_users = ratings_active.join(\n",
    "    overlap_users,\n",
    "    on=\"user_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Rows after removing isolated users:\", ratings_overlap_users.count())\n",
    "\n",
    "ratings_overlap_users.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b91111",
   "metadata": {},
   "source": [
    "6. Filter out books: \n",
    "- Each book must have >= 5 ratings\n",
    "- Remove books with extreme high/low rating given by few people\n",
    "\n",
    "Books with fewer than 5 ratings are removed because they do not provide enough data to compute reliable correlations with other books or users so that the similarity estimates will be more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccce9c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books kept after filering: 1247\n",
      "Rows after filtering unpopular / extreme books: 65292\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "|   isbn|user_id|rating|  book_title|         book_author|year_of_publication|           publisher|             Summary|Language|Category|\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "|2005018|      8|   5.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|2005018|  11400|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|2005018|  11676|   8.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|2005018|  85526|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "|2005018|  96054|   0.0|Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|In a small town i...|    NULL|    NULL|\n",
      "+-------+-------+------+------------+--------------------+-------------------+--------------------+--------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_unusual = ratings_overlap_users.groupBy(\"isbn\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"num_ratings\"),\n",
    "        F.avg(\"rating\").alias(\"avg_rating\")\n",
    "    )\n",
    "\n",
    "suspicious_books = (\n",
    "    (F.col(\"num_ratings\") <= 5) &\n",
    "    (\n",
    "        (F.col(\"avg_rating\") >= 9.5) |\n",
    "        (F.col(\"avg_rating\") <= 1.0)\n",
    "    )\n",
    ")\n",
    "\n",
    "books_keep = book_unusual.filter(\n",
    "    (F.col(\"num_ratings\") >= 5) &  \n",
    "    ~suspicious_books               \n",
    ").select(\"isbn\")\n",
    "\n",
    "print(\"Books kept after filering:\",\n",
    "      books_keep.count())\n",
    "\n",
    "ratings_filtered_books = ratings_overlap_users.join(\n",
    "    books_keep,\n",
    "    on=\"isbn\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Rows after filtering unpopular / extreme books:\",\n",
    "      ratings_filtered_books.count())\n",
    "\n",
    "ratings_filtered_books.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47d561",
   "metadata": {},
   "source": [
    "7. Remove duplicate books\n",
    "\n",
    "To remove duplicate books, we group editions by normalized (`title`,`author`) and select a canonical ISBN per group. All ratings for other editions are mapped to this canonical ISBN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee2c6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row number before merging editions: 65292\n",
      "Row number after merging editions to canonical ISBNs: 65292\n",
      "+---------+-------+------+---------------+-----------+-------------------+------------------------+---------------------------------------------------------------------+--------+--------+---------------+-----------+---------+----------+\n",
      "|isbn     |user_id|rating|book_title     |book_author|year_of_publication|publisher               |Summary                                                              |Language|Category|title_norm     |author_norm|isbn_can |isbn_final|\n",
      "+---------+-------+------+---------------+-----------+-------------------+------------------------+---------------------------------------------------------------------+--------+--------+---------------+-----------+---------+----------+\n",
      "|042518630|8067   |2.0   |Purity in Death|J.D. Robb  |2002               |Berkley Publishing Group|Eve Dallas must face the impossible: someone has unleashed a computer|NULL    |NULL    |purity in death|j.d. robb  |042518630|042518630 |\n",
      "|042518630|11676  |10.0  |Purity in Death|J.D. Robb  |2002               |Berkley Publishing Group|Eve Dallas must face the impossible: someone has unleashed a computer|NULL    |NULL    |purity in death|j.d. robb  |042518630|042518630 |\n",
      "|042518630|15819  |0.0   |Purity in Death|J.D. Robb  |2002               |Berkley Publishing Group|Eve Dallas must face the impossible: someone has unleashed a computer|NULL    |NULL    |purity in death|j.d. robb  |042518630|042518630 |\n",
      "|042518630|16634  |0.0   |Purity in Death|J.D. Robb  |2002               |Berkley Publishing Group|Eve Dallas must face the impossible: someone has unleashed a computer|NULL    |NULL    |purity in death|j.d. robb  |042518630|042518630 |\n",
      "|042518630|18979  |4.0   |Purity in Death|J.D. Robb  |2002               |Berkley Publishing Group|Eve Dallas must face the impossible: someone has unleashed a computer|NULL    |NULL    |purity in death|j.d. robb  |042518630|042518630 |\n",
      "+---------+-------+------+---------------+-----------+-------------------+------------------------+---------------------------------------------------------------------+--------+--------+---------------+-----------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize book_title and book_author\n",
    "ratings_norm = ratings_filtered_books.withColumn(\n",
    "    \"title_norm\",\n",
    "    F.lower(F.regexp_replace(F.col(\"book_title\"), r\"\\s+\", \" \"))\n",
    ").withColumn(\n",
    "    \"author_norm\",\n",
    "    F.lower(F.regexp_replace(F.col(\"book_author\"), r\"\\s+\", \" \"))\n",
    ")\n",
    "\n",
    "# Count the number of ratings for each ISBN within every (title_norm, author_norm, isbn) group.\n",
    "book_isbn_stats = ratings_norm.groupBy(\n",
    "    \"title_norm\", \"author_norm\", \"isbn\"\n",
    ").agg(\n",
    "    F.count(\"*\").alias(\"num_ratings_for_isbn\")\n",
    ")\n",
    "\n",
    "# For each (title_norm, author_norm) group, select the ISBN with the largest number of ratings as the canonical ISBN.\n",
    "w = Window.partitionBy(\"title_norm\", \"author_norm\") \\\n",
    "          .orderBy(F.col(\"num_ratings_for_isbn\").desc(), F.col(\"isbn\"))\n",
    "\n",
    "can_isbn_per_book = book_isbn_stats.withColumn(\n",
    "    \"rank_in_group\",\n",
    "    F.row_number().over(w)\n",
    ").filter(\n",
    "    F.col(\"rank_in_group\") == 1\n",
    ").select(\n",
    "    \"title_norm\", \"author_norm\", F.col(\"isbn\").alias(\"isbn_can\")\n",
    ")\n",
    "\n",
    "# Create mapping table\n",
    "isbn_with_norm = book_isbn_stats.select(\"title_norm\", \"author_norm\", \"isbn\")\n",
    "\n",
    "edition_to_rep = isbn_with_norm.join(\n",
    "    can_isbn_per_book,\n",
    "    on=[\"title_norm\", \"author_norm\"],\n",
    "    how=\"left\"\n",
    ").select(\n",
    "    \"isbn\", \"isbn_can\"\n",
    ")\n",
    "\n",
    "# Replace each edition’s ISBN in the ratings table with its corresponding canonical ISBN\n",
    "ratings_mapped = ratings_norm.join(\n",
    "    edition_to_rep,\n",
    "    on=\"isbn\",\n",
    "    how=\"left\"\n",
    ").withColumn(\n",
    "    \"isbn_final\",\n",
    "    F.coalesce(F.col(\"isbn_can\"), F.col(\"isbn\"))  \n",
    ")\n",
    "\n",
    "# In the ratings table, a single user may have rated multiple editions of the same logical book. \n",
    "# Therefore, we aggregate the data by (user_id, isbn_final) to ensure that each user–book pair has only one rating.\n",
    "ratings_rep_books = ratings_mapped.groupBy(\n",
    "    \"user_id\", \"isbn_final\"\n",
    ").agg(\n",
    "    F.avg(\"rating\").alias(\"rating\"),               \n",
    "    F.count(\"*\").alias(\"num_times\"),               \n",
    "    F.first(\"book_title\").alias(\"book_title\"),\n",
    "    F.first(\"book_author\").alias(\"book_author\"),\n",
    "    F.first(\"year_of_publication\").alias(\"year_of_publication\"),\n",
    "    F.first(\"publisher\").alias(\"publisher\"),\n",
    "    F.first(\"Summary\").alias(\"Summary\"),\n",
    "    F.first(\"Language\").alias(\"Language\"),\n",
    "    F.first(\"Category\").alias(\"Category\")\n",
    ").withColumnRenamed(\n",
    "    \"isbn_final\", \"isbn\"   \n",
    ")\n",
    "\n",
    "print(\"Row number before merging editions:\", ratings_mapped.count())\n",
    "print(\"Row number after merging editions to canonical ISBNs:\", ratings_mapped.count())\n",
    "ratings_mapped.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ccda6",
   "metadata": {},
   "source": [
    "8. Merge duplicates: Only one rating is retained for each user and each book\n",
    "\n",
    "Users may have rated the same book several times, for exemple, rating the same book which has different versions twice.\n",
    "If a user rated the same book twice, keep the highest rating. We keep one copy of book metadata (using `.first()`) and book metadata will be cleaned and reconstructed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05752ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row number before deduplication: 65292\n",
      "Row number after deduplication: 65056\n",
      "+-------+---------+------+---------+---------------------------------------------------------------------------------------------+-----------------+-------------------+----------------+----------------------------------------------------------------------+--------+--------+\n",
      "|user_id|isbn     |rating|num_times|book_title                                                                                   |book_author      |year_of_publication|publisher       |Summary                                                               |Language|Category|\n",
      "+-------+---------+------+---------+---------------------------------------------------------------------------------------------+-----------------+-------------------+----------------+----------------------------------------------------------------------+--------+--------+\n",
      "|100009 |385504209|8.0   |1        |The Da Vinci Code                                                                            |Dan Brown        |2003               |Doubleday       |Harvard symbologist Robert Langdon and French cryptologist Sophie     |NULL    |NULL    |\n",
      "|100009 |60502258 |6.0   |1        |The Divine Secrets of the Ya-Ya Sisterhood: A Novel                                          |Rebecca Wells    |2002               |HarperTorch     |SiddaLee has escaped her Louisiana hometown to become a theatrical    |NULL    |NULL    |\n",
      "|100115 |345465083|0.0   |1        |Seabiscuit                                                                                   |LAURA HILLENBRAND|2003               |Ballantine Books|Retraces the journey of Seabiscuit, a horse with crooked legs and a   |NULL    |NULL    |\n",
      "|100115 |786868716|10.0  |1        |The Five People You Meet in Heaven                                                           |Mitch Albom      |2003               |Hyperion        |With a timeless tale, appealing to all, this is a book that readers of|NULL    |NULL    |\n",
      "|100223 |316789089|9.0   |1        |The Pilot's Wife : A Novel Tag: Author of the Weight of Water (Oprah's Book Club (Hardcover))|Anita Shreve     |1999               |Little, Brown   |9                                                                     |9       |9       |\n",
      "+-------+---------+------+---------+---------------------------------------------------------------------------------------------+-----------------+-------------------+----------------+----------------------------------------------------------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_merged = ratings_mapped.groupBy(\n",
    "    \"user_id\", \"isbn_final\"\n",
    ").agg(\n",
    "    F.max(\"rating\").alias(\"rating\"),               \n",
    "    F.count(\"*\").alias(\"num_times\"),               \n",
    "    F.first(\"book_title\").alias(\"book_title\"),\n",
    "    F.first(\"book_author\").alias(\"book_author\"),\n",
    "    F.first(\"year_of_publication\").alias(\"year_of_publication\"),\n",
    "    F.first(\"publisher\").alias(\"publisher\"),\n",
    "    F.first(\"Summary\").alias(\"Summary\"),\n",
    "    F.first(\"Language\").alias(\"Language\"),\n",
    "    F.first(\"Category\").alias(\"Category\")\n",
    ").withColumnRenamed(\n",
    "    \"isbn_final\", \"isbn\"   \n",
    ")\n",
    "\n",
    "print(\"Row number before deduplication:\", ratings_mapped.count())\n",
    "print(\"Row number after deduplication:\", ratings_merged.count())\n",
    "ratings_merged.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9227c",
   "metadata": {},
   "source": [
    "We first materialize an intermediate cleaned dataset (`ratings_merged`) before running k-core. This \"cut\" breaks the long Spark lineage (raw → cleaning → ISBN normalization → deduplication), so the later k-core iterations run on a compact, stable table instead of recomputing the whole pipeline every time.\n",
    "\n",
    "Due to stability and filesystem limitations of Spark on Windows (Hadoop + `winutils.exe` + local permissions), writing intermediate results directly with `df.write.parquet(...)` was unreliable in my environment. As a workaround, we used `toPandas()` **only to export** the already cleaned Spark DataFrame (`ratings_merged_for_core`) to disk (Parquet), and then reloaded this file back into Spark in a fresh session for the k-core iterations and all downstream processing. \n",
    "\n",
    "Pandas is **not used for any filtering, aggregation, or modeling steps**; it serves purely as a lightweight I/O bridge to materialize a stable checkpoint between two Spark stages.\n",
    "\n",
    "Then we apply an iterative 5-core on the user–item graph (users and books as nodes, ratings as edges), shown in data_cleaning_02.ipynb. In practice, this means repeatedly removing users with fewer than 5 ratings and books with fewer than 5 ratings (and extreme low-support items). The result is a denser, more reliable interaction subgraph where both users and books have enough data to compute meaningful similarities and train recommendation models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd3f67",
   "metadata": {},
   "source": [
    "[x] 1. if all `ratings` are within the range [0,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65056, 10)\n",
      "Saving to: D:\\projet_esilv\\Mining\\export_core\\ratings_merged_for_core.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cutting the ligeage and exporting the cleaned core ratings \n",
    "\n",
    "ratings_merged_for_core = ratings_merged.select(\n",
    "    \"user_id\",\n",
    "    \"isbn\",\n",
    "    \"rating\",\n",
    "    \"book_title\",\n",
    "    \"book_author\",\n",
    "    \"year_of_publication\",\n",
    "    \"publisher\",\n",
    "    \"Summary\",\n",
    "    \"Language\",\n",
    "    \"Category\"\n",
    ")\n",
    "\n",
    "pdf_core = ratings_merged_for_core.toPandas()\n",
    "print(pdf_core.shape)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if getattr(sys, 'frozen', False):  \n",
    "    base_dir = os.path.dirname(sys.executable)\n",
    "else:  \n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "out_dir = os.path.join(base_dir, \"export_core\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(out_dir, \"ratings_merged_for_core.parquet\")\n",
    "print(\"Saving to:\", output_path)\n",
    "\n",
    "pdf_core.to_parquet(output_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
